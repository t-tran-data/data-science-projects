{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf0e9436-837d-4ca4-ae7e-d2c75f2a93ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Regression-PCA-Regularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b19bbc-1587-4a7b-9f49-90ea5a82cf3d",
   "metadata": {},
   "source": [
    "**Linear Regression: Train/Test Split and Metric Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62d12ee8-0988-470d-a183-9d9dca2d5190",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset from \"data.csv\"\n",
    "pd.set_option(\"display.notebook_repr_html\", False)  # disable \"rich\" output\n",
    "data = pd.read_excel(\"Real estate valuation data set.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56a98900-dcf9-405e-b738-4abc8eb17a91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 54.59884830498824\n",
      "Mean Absolute Error: 5.418032735899282\n",
      "R^2 Score: 0.6745414195692352\n"
     ]
    }
   ],
   "source": [
    "#******************************************************************************************************************\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "#******************************************************************************************************************\n",
    "#****** Define X and Y variables in the dataset\n",
    "X = data.drop(columns=[\"Y house price of unit area\"])\n",
    "y = data[\"Y house price of unit area\"]\n",
    "\n",
    "#****** split the dataset into training and test datasets (80-20 split, test size = 20%, training size 80%)\n",
    "X_train_data_1, X_test_data_1, y_train_data_1, y_test_data_1 = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_data_1, y_train_data_1)\n",
    "\n",
    "y_pred = model.predict(X_test_data_1)\n",
    "\n",
    "#******************************************************************************************************************\n",
    "#****** Check model\n",
    "mse_1 = mean_squared_error(y_test_data_1, y_pred)\n",
    "mae_1 = mean_absolute_error(y_test_data_1, y_pred)\n",
    "r2_1 = r2_score(y_test_data_1, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse_1)\n",
    "print(\"Mean Absolute Error:\", mae_1)\n",
    "print(\"R^2 Score:\", r2_1)\n",
    "\n",
    "#******************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7bbd58-09ae-4b3a-80ba-f3e5eb3a9a8f",
   "metadata": {},
   "source": [
    "Mean squared error (MSE) is the squared average difference between the predicted data and the actual data.\n",
    "Mean absolute error (MAE) is the absolute average difference between the predicted data and the actual data.\n",
    "R squared describes how well the model is in regard to predict the data. R square is ranged from 0 to 1 with 1 being a good model.\n",
    "In this question 1, the results for MSE, MAE are 54.6 and 5.42 respectively. These results do not imply a good model. However, the R squared is 0.67 which suggests that 67% of the variance are in the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c33bfb5-62e8-43ae-bc7c-3cafde00b5d5",
   "metadata": {},
   "source": [
    "**Dimensionality reduction with PCA and Linear regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a36363c-515f-432a-9095-ad49f2fa6730",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for model with and without PCA: 58.774641855017535 & 54.59884830498824\n",
      "Mean Absolute Error for model with and without PCA: 5.82883266736958 & 5.418032735899282\n",
      "R^2 Score for model with and without PCA: 0.6496499084264935 & 0.6745414195692352\n"
     ]
    }
   ],
   "source": [
    "#******************************************************************************************************************\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#******************************************************************************************************************\n",
    "#****** Apply StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#****** Apply PCA\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "#****** Split the PCA transformed dataset into 80-20 split\n",
    "X_train_pca, X_test_pca, y_train_data_2, y_test_data_2 = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#****** Linear Regression\n",
    "model_pca = LinearRegression()\n",
    "model_pca.fit(X_train_pca, y_train_data_2)\n",
    "\n",
    "y_pred_pca = model_pca.predict(X_test_pca)\n",
    "\n",
    "#******************************************************************************************************************\n",
    "\n",
    "mse_pca = mean_squared_error(y_test_data_2, y_pred_pca)\n",
    "mae_pca = mean_absolute_error(y_test_data_2, y_pred_pca)\n",
    "r2_pca = r2_score(y_test_data_2, y_pred_pca)\n",
    "\n",
    "print(\"Mean Squared Error for model with and without PCA:\", mse_pca, \"&\", mse_1)\n",
    "print(\"Mean Absolute Error for model with and without PCA:\", mae_pca, \"&\", mae_1)\n",
    "print(\"R^2 Score for model with and without PCA:\", r2_pca, \"&\", r2_1)\n",
    "\n",
    "#******************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737d5378-cde5-4e05-a12c-e7a5925b4aed",
   "metadata": {},
   "source": [
    "Compared to the model built in question 1, the PCA model in question 2 has lower MSE, MAE and R squared. This explains that the original model in question 1 provides a better performance in predicting data.\n",
    "It is suggested that the less effective outcome of the model in question 2 could be due to using PCA and selecting only the first three principal components. These first three components may not include enough information for the entirety of the dataset, thus yielding loss of information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fae657d-dfd3-4199-ac64-f0d574c5c794",
   "metadata": {},
   "source": [
    "**Logistic Regression with PCA on the Iris Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c583011f-fdb6-491c-bcde-23ba4441d0ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import IRIS dataset from Sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "X_iris = iris_data.data\n",
    "y_iris = iris_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf711c34-70c6-4b20-b548-da8ea759e154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#******************************************************************************************************************\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#******************************************************************************************************************\n",
    "#****** Apply StandardScaler to standardise the features\n",
    "scaler_3 = StandardScaler()\n",
    "X_scaled_3 = scaler.fit_transform(X_iris)\n",
    "\n",
    "#****** Apply PCA to select the first three principal components\n",
    "pca_3 = PCA(n_components=3)\n",
    "X_iris_pca = pca.fit_transform(X_scaled_3)\n",
    "\n",
    "#******************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5faae74c-6b69-4149-87d9-b12ce82c1dc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics:\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "#******************************************************************************************************************\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "#******************************************************************************************************************\n",
    "# Split the dataset into training and testing sets (80-20 split)\n",
    "X_train_data_3, X_test_data_3, y_train_data_3, y_test_data_3 = train_test_split(X_iris_pca, y_iris, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a logistic regression model\n",
    "log_reg_model = LogisticRegression()\n",
    "log_reg_model.fit(X_train_data_3, y_train_data_3)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_3 = log_reg_model.predict(X_test_data_3)\n",
    "\n",
    "#******************************************************************************************************************\n",
    "# Performance evaluation\n",
    "accuracy = accuracy_score(y_test_data_3, y_pred_3)\n",
    "precision = precision_score(y_test_data_3, y_pred_3, average='weighted')\n",
    "recall = recall_score(y_test_data_3, y_pred_3, average='weighted')\n",
    "f1 = f1_score(y_test_data_3, y_pred_3, average='weighted')\n",
    "\n",
    "print(\"Performance metrics:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "#******************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdaba68-2943-47b1-a175-5d1d2be8ccc2",
   "metadata": {},
   "source": [
    "Theoretically, accuracy score indicates the proportion of true positive over the total predictions. This means an accuracy score of 1 indicates that all classifying predictions are correct.\n",
    "\n",
    "Precision is the proportion of true positive predictions over all positive predictions. This means a precision score of 1 indicates that there is no false positive classification.\n",
    "\n",
    "Recall is the proportion of true positive predictions over actual positive instances. This means a recall score of 1 indicates all positive instances are correctly classified.\n",
    "\n",
    "F1 is the harmonic mean of precision and recall.\n",
    "\n",
    "In this model, all scores are 1 which imply that the logistic model is working perfectly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2392497-9186-47d3-8bde-9d85449206b4",
   "metadata": {},
   "source": [
    "**Regularisation in Logistic Regression: L1 and L2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7ba405b-2599-45c6-888b-54a807b6387a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in the previous model and this model: 1.0 & 1.0\n",
      "Precision in the previous model and this model: 1.0 & 1.0\n",
      "Recall in the previous model and this model: 1.0 & 1.0\n",
      "F1 Score in the previous model and this model: 1.0 & 1.0\n"
     ]
    }
   ],
   "source": [
    "#******************************************************************************************************************\n",
    "\n",
    "reg_log_reg_model = LogisticRegression(penalty='l2')\n",
    "reg_log_reg_model.fit(X_train_data_3, y_train_data_3)\n",
    "\n",
    "y_pred_reg = reg_log_reg_model.predict(X_test_data_3)\n",
    "\n",
    "#******************************************************************************************************************\n",
    "#****** Comparing with the previous model\n",
    "accuracy_reg = accuracy_score(y_test_data_3, y_pred_reg)\n",
    "precision_reg = precision_score(y_test_data_3, y_pred_reg, average='weighted')\n",
    "recall_reg = recall_score(y_test_data_3, y_pred_reg, average='weighted')\n",
    "f1_reg = f1_score(y_test_data_3, y_pred_reg, average='weighted')\n",
    "\n",
    "print(\"Accuracy in the previous model and this model:\", accuracy, \"&\", accuracy_reg)\n",
    "print(\"Precision in the previous model and this model:\", precision, \"&\", precision_reg)\n",
    "print(\"Recall in the previous model and this model:\", recall, \"&\", recall_reg)\n",
    "print(\"F1 Score in the previous model and this model:\", f1, \"&\", f1_reg)\n",
    "\n",
    "#******************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f31fb22-bc32-4191-b124-23f1461718e4",
   "metadata": {},
   "source": [
    "L2 regularisation model has all scores being 1 which implies that the model using L2 regularisation works perfectly.\n",
    "Compared to the scores achieved in Question 3, L2 regularisation produces a logistic regression model that can work just as good."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
